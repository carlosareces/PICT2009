This project aims to achieve a balance between a system which is 
 sufficiently generic to be applicable in different areas, and 
specific enough to benefit from the efficient use of existing 
techniques for knowledge management, planning and natural language processing.
Designing and implementing such a system is a multidisciplinary effort leading 
to research in diverse scientific areas:

\paragraph{Pragmatics}$\hspace*{-.4cm}$ is an interdisciplinary field which
integrates insights from linguistics (e.g., 
conversational implicatures~\cite{grice75}),
sociology (e.g., conversational analysis~\cite{schegloff87b}) and
philosophy (e.g., theory of speech acts~\cite{austin62}). It aims to explore how
the context (in which a conversation is situated) contributes to the meaning (of
everything that is said during that conversation). The meaning conveyed during
a conversation depends not only on linguistic information (entities in focus,
grammatical and morphological rules, etc.) but also on extra-linguistic
information (physical situation of conversation, previous
experiences of speakers, etc.). As a result, the same sentence may mean
different things in different contexts. The area of pragmatics studies the
pragmatic process by which a sentence is disambiguated using its context.

A dialogue system needs to have pragmatic capabilities in order to interact in a
natural way with its users. In particular, a system must define what kind of
contextual information should be represented; and what inference tasks on a
sentence and context are necessary in order to interpret an utterance. In such a
system it is important that sentences makes explicit the right amount of
information: too much information
will delay and bore the user, but if the information is not enough the user 
will not know how to perform the task and make mistakes.

One of the major contributions of the project in this area will be a virtual 
laboratory for pragmatic theories that consist of a controlled environment 
for studying the
interaction set in a world where physical actions and language intermingle.
The prototype will let us investigate the impact that different
intruction giving policies (e.g., post order on the tree structure of the task)
have on the successful completion of the task. Similar studies have been done
before (e.g.,~\cite{foster-etal-ijcai2009}) but they usually assume a predetermined
task. Since our prototype allows for the specification of the virtual world,
the available actions, and the goal, we will be able to determine when the impact
associated to a particular policy is dependent on the task or not.
We will also investigate short and long term repairs.
Repairs are usually caused by conversational implicatures~\cite{benotti09c}.
Modeling these implicatures in a generic dialogue system is difficult because 
they are too open ended. However, since the present prototype provides a situated 
interaction, restricted to the virtual world, it will be possible to test the 
relationship between implicatures, the type of repairs they give rise to, 
and the inference tasks needed to predict them. 

\paragraph{Inference}$\hspace*{-.4cm}$ can be understood as any operation that
transforms implicit information in explicit information. This definition is
general enough to cover tasks ranging from logical inference (i.e., deduction in
a formal language) to inference tasks common in AI (e.g., planning and
non-monotonic inference), as well as statistical operations (e.g. obtaining
estimators on a data set). A dialogue system has to
continually perform inference operations. E.g., inference is needed
to interpret information received from the user, incorporate it to 
the system's data repository, and then decide what should be conveyed 
back to the user.
The very problem of deciding what kind of logical representation and what type
of inference to use in a given situation is complex (propositional logic vs.\
first-order logic, validity vs.\ model checking, logical inference vs.\
statistical inference). Independently of which type of inference is used, they are usually computationally expensive. The challenge here is to find the appropriate
balance between the expressivity of the representation formalism and the
cost of the required inference methods.

The main contribution of the project in this area is in
the design, development and study of planning algorithms. A typical planning
system takes three inputs --initial state, possible
actions and expected goal-- and returns a sequence of actions (a plan)
that when sequentially applied to the initial state, ends in a state that
satisfies the goal. Different methods to obtain a plan have been studied
(forward chaining, backward chaining, coding in terms of propositional
satisfiability, etc.), and they are currently implemented in systems 
that can solve many planning tasks efficiently.
However, most of these systems make assumptions that simplify the problem
(deterministic atomic time, complete information, absence of a background theory, etc.). And
most of them return a single plan. We will investigate algorithms
that eliminate some of these simplifications (in particular, we will 
study planning with incomplete information and based on a background theory). 
We will also provide extended planning services: alternative plans, minimal
plans, conditional plans, incomplete plans, affordability of a given
state, etc.

\paragraph{Evaluation}$\hspace*{-.4cm}$  of natural language generation systems
is one of the most difficult tasks in the area of NLP. A given concept can be 
expressed in many different ways, all of them correct. 
Hence, it is not possible to determining the quality of a
generated sentence simply by, for example, comparing 
the result with a gold standard. The problem of absence of gold standards is shared
with another area of the NLP, namely Machine Translation, for which
various evaluation methodologies, both direct and indirect, have been proposed. 
Direct methods applies a metric to the text
generated by the system, while indirect methods evaluates the performance of the
system through the use of the generated text to perform some task. But
none of these methods is a standard and generally accepted methodology, which has
been proven to be effective in all cases.
Since what is being evaluated in this project is a system that interacts via the
generation of natural language instructions, we can determine its performance
through quantitative metrics (e.g., average task completion time), 
qualitative metrics (e.g., general user satisfaction) and metrics based on the
context (e.g., how well the system addressed the user needs in particular situations).
We will study the portability of evaluation techniques from the domain of machine
translation and multimodal human-computer interaction to the evaluation of the system
proposed in this project.

One of the main contributions of our project at this respect is the
integration of assessment techniques from different areas into a methodology for
evaluating dialog systems for virtual environments, aiming to estimate their
usability and effectiveness. This methodology could be used both to determine
whether a system is suitable for a task type and user, and to compare the
performance of different systems of the same type.
Another contribution will be the study and application of software evaluation standards
to the developed systems, creating a standardized quality model and proposing
a set of appropriate metrics to assess each of the aspects of the model. 
Finally, the annotated corpus of human-human interaction, together with the corpus of
human-machine interaction collected during the project will be made public. Such
corpora will serve, for example, to design more general platforms for evaluating
dialog systems, going beyond the aspects evaluated by existing
platforms like GIVE.

\paragraph{Impact in the Argentinean Landscape:} 
Natural language processing, and in particular the development of dialogue
systems is a rapidly growing area in developed countries; the automatic
processing of natural language has become a strategic capability for companies,
institutions and the wider community. However, this area is extremely
underdeveloped in Argentina. This can be attributed to several factors. (a) The
relative youth of the area of NLP, which implies a relative dearth of trained
professionals throughout the world. (b) The underdevelopment of the whole area
of research in computer science, for historical reasons and industry demand. (c)
The undeveloped area of Artificial Intelligence and Formal Linguistics in
Argentina, also for historical and academic reasons. (d) Poor interaction
between the few researchers in NLP that are in the region. 

It seems clear that NLP is a strategic research area for Argentina, which can
achieve academic excellence and industry worldwide. We believe in supporting the
development of this area by promoting the following. (a) Training of human
resources through doctoral programs and courses taught in Argentina by
internationally renowned professionals. (b) Incorporation of trained human
resources to contribute to the growth and diversification of the critical mass
in the area. (c) Improving the interaction between various groups or
individual researchers in NLP, through the organization of workshops, courses,
visiting professors, co-tutoring, coordinated specialty programs, etc.


In particular, the topics investigated in the framework of this project are of
relevance in the current Argentinean landscape for at least two reasons.

On the one hand, the project integrates and develops various key aspects of the
area of computational linguistics (syntax, semantics, pragmatics,
representation, inference, evaluation). Computational linguistics
and its application to automatic processing of natural language had a major
development in recent years, but the area is today almost 
nonexistent in Argentina. This project will be a step towards reversing this situation. 
On the other hand, the ultimate goal of the project is to investigate
the use of the 
developed platform for distance education (specifically, as a tool for
language learning). Distance education is a valuable resource to overcome the problem of
centralization of educational resources in the country. 
