This project aims to achieve a balance between a system which is 
 sufficiently generic to be applicable in different areas, and 
specific enough to benefit from the efficient use of existing 
techniques for knowledge management, planning and natural language processing.
Designing and implementing such a system is a multidisciplinary effort leading 
to research in diverse scientific areas:

\paragraph{Pragmatics}$\hspace*{-.4cm}$ is an interdisciplinary field which
integrates insights from linguistics (e.g., 
conversational implicatures~\cite{grice75}),
sociology (e.g., conversational analysis~\cite{schegloff87b}) and
philosophy (e.g., theory of speech acts~\cite{austin62}). It aims to explore how
the context (in which a conversation is situated) contributes to the meaning (of
everything that is said during that conversation). The meaning conveyed during
a conversation depends not only on linguistic information (entities in focus,
grammatical and morphological rules, etc.) but also on extra-linguistic
information (physical situation of conversation, previous
experiences of speakers, etc.). As a result, the same sentence may mean
different things in different contexts. The area of pragmatics studies the
process by which a sentence is disambiguated using its context. In pragmatics,
there is a distinction between sentence (grammatical form that
the linguistic act takes) and utterance (sentence plus its context). The ability
to understand a sentence using its context, i.e. the ability to understand an
utterance, is called pragmatic competence. Explaining the pragmatic competence
involves explaining how a person makes inferences about a sentence and its
context to properly interpret the meaning that the speaker intends to convey.

A dialogue system needs to have pragmatic capabilities in order to interact in a
natural way with its users. In particular, a system must define what kind of
contextual information should be represented; and what inference tasks on a
sentence and context are necessary in order to interpret an utterance. Properly 
identifying this issues will have a crucial impact on the performance of a system
like the one we propose to develop. In such a system it is indispensable that
sentences makes explicit the right amount of information: too much information
will delay and bore the user, but if the information is not enough the user 
will not know how to perform the task and make mistakes.

One of the major contributions of the project in this area will be a virtual 
laboratory for pragmatic theories that consist of a controlled environment 
for studying the
interaction set in a world where physical actions and language intermingle.

The prototype will let us investigate the impact that different
intruction giving policies (e.g., post order on the tree structure of the task)
have on the successful completion of the task. Similar studies have been done
before (e.g.,~\cite{foster-etal-ijcai2009}) but they usually assume a predetermined
task. Since our prototype allows for the specification of the virtual world,
the available actions, and the goal, we will be able to determine when the impact
associated to a particular policy is dependent on the task or not.

We will also investigate short and long term repairs.
Repairs are usually caused by conversational implicatures~\cite{benotti09c}.
Modeling these implicatures in a generic dialogue system is difficult because 
they are too open ended. However, since the present prototype provides a situated 
interaction, restricted to the virtual world, it will be possible to test the 
relationship between implicatures, the type of repairs they give rise to, 
and the inference tasks needed to predict them. 

\paragraph{Inference}$\hspace*{-.4cm}$ can be understood as any operation that
transforms implicit information in explicit information. This definition is
general enough to cover tasks ranging from logical inference (i.e., deduction in
a formal language) to inference tasks common in AI (e.g., planning and
non-monotonic inference), as well as statistical operations (e.g. obtaining
estimators on a data set). A dialogue system has to
continually perform inference operations. E.g., inference is needed
to interpret information received from the user, incorporate it to 
the system's data repository, and then decide what should be conveyed 
back to the user.
The very problem of deciding what kind of logical representation and what type
of inference to use in a given situation is complex (propositional logic vs.\
first-order logic, validity vs.\ model checking, logical inference vs.\
statistical inference). Independently of which type of inference is used, they are usually computationally expensive. The challenge here is to find the appropriate
balance between the expressivity of the representation formalism and the
cost of the required inference methods.

The main contribution of the project in this area is in
the design, development and study of planning algorithms. A typical planning
system takes three inputs --an initial state, a specification of possible
actions and an expected goal-- and returns a sequence of actions (a plan)
that when sequentially applied to the initial state, ends in a state that
satisfies the goal. Different methods to obtain a plan have been studied
(forward chaining, backward chaining, coding in terms of propositional
satisfiability, etc.), and they are currently implemented in systems 
that can solve many planning tasks efficiently.
However, most of these systems make assumptions that simplify the problem
(deterministic atomic time, complete information, absence of a background theory, etc.). And
most of them return a single plan. We will investigate algorithms
that eliminate some of these simplifications (in particular, we will 
study planning with incomplete information and based on a background theory). 
We will also provide extended planning services: alternative plans, minimal plans, conditional plans, incomplete plans, possible next actions in a give state, etc.

\paragraph{Evaluation}$\hspace*{-.4cm}$  of natural language generation systems
is one of the most difficult tasks in the area of NLP. A given concept can be 
expressed in many different ways, all of them correct. 
Hence, it is not possible to determining the quality of a
generated sentence simply by, for example, comparing 
the result with a gold standard. The problem of absence of gold standards is shared
with another area of the NLP, namely Machine Translation, for which
various evaluation methodologies, both direct and indirect, have been proposed. 
Direct methods applies a metric to the text
generated by the system, while indirect methods evaluates the performance of the
system through the use of the generated text to perform some task. But
none of these methods is a standard and generally accepted methodology, which has
been proven to be effective in all cases.
Since what is being evaluated in this project is a system that interacts via the
generation of natural language instructions, we can determine its performance
through quantitative metrics (e.g., average task completion time), 
qualitative metrics (e.g., general user satisfaction) and metrics based on the
context (e.g., how well the system addressed the user needs in particular situations).
We will study the portability of evaluation techniques from the domain of machine
translation and multimodal human-computer interaction to the evaluation of the system
proposed in this project.

One of the main contributions of our project at this respect is the
integration of assessment techniques from different areas into a methodology for
evaluating dialog systems for virtual environments, aiming to estimate their
usability and effectiveness. This methodology could be used both to determine
whether a system is suitable for a task type and user, and to compare the
performance of different systems of the same type.
Another contribution will be the study and application of software evaluation standards
to the developed systems, creating a standardized quality model and proposing
a set of appropriate metrics to assess each of the aspects of the model. 
Finally, the annotated corpus of human-human interaction, together with the corpus of
human-machine interaction collected during the project will be made public. Such
corpora will serve, for example, to design more general platforms for evaluating
dialog systems, going beyond the aspects evaluated by existing
platforms like GIVE.

\paragraph{Impact in the Argentinean Landscape:} The topics investigated in the 
framework of this project are of relevance in the
current Argentine landscape for at least two reasons.

On the one hand, the project integrates and develops various key aspects of the
area of computational linguistics (syntax, semantics, pragmatics,
representation, inference, evaluation). Computational linguistics
and its application to automatic processing of natural language had a major
development in recent years, but the area is today almost 
nonexistent in Argentina. This project will be a step towards reversing this situation. 
Moreover, the ultimate goal of the project is to investigate the use of the 
developed platform for distance education (specifically, as a tool for
language learning). Distance education is a valuable resource to overcome the problem of
centralization of educational resources in the country. 


However, developing appropriate tools in this specific area is difficult.
To develop distance learning systems is essential to model the user's learning
progress. This requires a system aware of the evolution of the
user, and that takes into account their achievements and their problems. This type
of interaction between user and system can be modeled as a dialogue, which
records the acquired knowledge context (of the user about the course material, and
of the system about to user). Managing this kind of dialogue is particularly interesting,
since the system must be able to interpret requirements, and generate
appropriate responses, for non-experts uses whose knowledge evolves during the
interaction. Moreover, the system must be able to properly represent both the
information concerning the course material, and information about the
evolution of the user. For example, the system must be able to diagnose what
part of the course material should be reviewed from the wrong answers of the
user. Finally, the system must be able to evaluate the user interaction in order
to decide which learning objectives have been achieved. The theoretical and practical
results obtained during the project directly contribute to solving these difficult
problems.




